import pandas as pd
import numpy as np
import os
from tqdm import tqdm

# ===================== å…¨å±€é…ç½®ï¼ˆè´´åˆæ¯”èµ›ç›®å½•/è§„åˆ™ï¼Œå¯æŒ‰éœ€å¾®è°ƒï¼‰=====================
# ç›®å½•ç»“æ„ï¼ˆåŸå§‹æ•°æ®/å¤„ç†åæ•°æ®è·¯å¾„
DATA_ROOT = os.path.join("data")    # åŸå§‹æ•°æ®ï¼šdata/1/A.csv ~ data/5/E.csv
OUTPUT_ROOT = os.path.join("output")# è¾“å‡ºæ•°æ®ï¼šå•è‚¡æ¸…æ´—/å¤šè‚¡é¢æ¿/æŒ‡æ ‡æ•°æ®
# æ¯”èµ›å›ºå®šå‚æ•°
STOCK_CODES = ["A", "B", "C", "D", "E"]       # æ¿å—5åªè‚¡ç¥¨ï¼ŒEä¸ºé¢„æµ‹åŸºå‡†
TRADING_DAYS = ["1", "2", "3", "4", "5"]      # 5ä¸ªäº¤æ˜“æ—¥
TIME_INTERVAL = 500                           # æ—¶é—´æˆ³æ­¥é•¿ï¼š500ms
# äº¤æ˜“æ—¶æ®µè§„åˆ™ï¼ˆHHMMSSmmmæ ¼å¼ï¼Œä¸¥æ ¼å‰”é™¤11:30-13:00åˆä¼‘ï¼‰
TRADING_RULES = {
    "morning_start": 93000000,    # 09:30:00.000
    "morning_end": 112959500,     # 11:29:59.500
    "afternoon_start": 130000000, # 13:00:00.000
    "afternoon_end": 145000000    # 14:50:00.000
}
# æ ¸å¿ƒå­—æ®µå®šä¹‰ï¼ˆè¦†ç›–æ¯”èµ›åŸç”Ÿå­—æ®µï¼Œåˆ†ç±»ç®¡ç†æ–¹ä¾¿å¤„ç†ï¼‰
CORE_COLS = [
    "Time", "BidPrice1", "BidPrice2", "BidPrice3", "BidPrice4", "BidPrice5",
    "BidVolume1", "BidVolume2", "BidVolume3", "BidVolume4", "BidVolume5",
    "AskPrice1", "AskPrice2", "AskPrice3", "AskPrice4", "AskPrice5",
    "AskVolume1", "AskVolume2", "AskVolume3", "AskVolume4", "AskVolume5",
    "OrderBuyNum", "OrderSellNum", "OrderBuyVolume", "OrderSellVolume",
    "TradeBuyNum", "TradeSellNum", "TradeBuyVolume", "TradeSellVolume",
    "TradeBuyAmount", "TradeSellAmount", "LastPrice", "Return5min"
]
PRICE_COLS = [col for col in CORE_COLS if "Price" in col] + ["LastPrice"]
VOLUME_COLS = [col for col in CORE_COLS if "Volume" in col]
BID_VOL_COLS = [col for col in CORE_COLS if "BidVolume" in col]
AMOUNT_COLS = ["TradeBuyAmount", "TradeSellAmount"]
ORDER_NUM_COLS = [col for col in CORE_COLS if "Num" in col]

# ===================== å·¥å…·å‡½æ•°ï¼šç›®å½•åˆå§‹åŒ– =====================
def init_directories():
    """åˆå§‹åŒ–è¾“å‡ºç›®å½•ï¼ŒæŒ‰äº¤æ˜“æ—¥/å•è‚¡/å¤šè‚¡/æŒ‡æ ‡åˆ†å±‚"""
    for day in TRADING_DAYS:
        os.makedirs(os.path.join(OUTPUT_ROOT, day, "single_stock"), exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_ROOT, "multi_stock_panel"), exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_ROOT, "indicators"), exist_ok=True)
    print("âœ… ç›®å½•åˆå§‹åŒ–å®Œæˆ")

# ===================== æ ¸å¿ƒ1ï¼šåŠ è½½æ•°æ®ï¼ˆé€‚é…æ¯”èµ›ç›®å½•ç»“æ„ï¼‰=====================
def load_data(day: str, stock_code: str) -> pd.DataFrame:
    """
    åŠ è½½å•äº¤æ˜“æ—¥å•è‚¡ç¥¨åŸå§‹æ•°æ®
    :param day: äº¤æ˜“æ—¥ï¼ˆ1/2/3/4/5ï¼‰
    :param stock_code: è‚¡ç¥¨ä»£ç ï¼ˆA/B/C/D/Eï¼‰
    :return: æ¸…æ´—å­—æ®µåçš„åŸå§‹DataFrame
    """
    file_path = os.path.join(DATA_ROOT, day, f"{stock_code}.csv")
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"åŸå§‹æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")
    
    # è¯»å–æ•°æ®ï¼ŒæŒ‡å®šå­—æ®µç±»å‹ï¼Œè¿‡æ»¤å†—ä½™åˆ—
    df = pd.read_csv(
        file_path,
        usecols=CORE_COLS,
        dtype={
            "Time": np.int64,
            **{col: np.int64 for col in PRICE_COLS + VOLUME_COLS + ORDER_NUM_COLS},
            **{col: np.float64 for col in AMOUNT_COLS},
            "Return5min": np.float64
        },
        na_values=["", "NaN", "null", "-"]
    )
    print(f"ğŸ“¥ åŠ è½½å®Œæˆï¼š{day}æ—¥-{stock_code}ï¼ŒåŸå§‹è¡Œæ•°ï¼š{df.shape[0]}")
    return df

# ===================== æ ¸å¿ƒ2ï¼šå•è‚¡å¤„ç†ï¼ˆæ¸…æ´—+å¯¹é½+æ ‡å‡†åŒ–ï¼‰=====================
def process_single_stock(day: str, stock_code: str) -> pd.DataFrame:
    """
    å•è‚¡å®Œæ•´å¤„ç†æµç¨‹ï¼šåŠ è½½â†’å»é‡æ’åºâ†’æ—¶æ®µè¿‡æ»¤â†’å¼‚å¸¸å€¼æ¸…æ´—â†’500mså¯¹é½â†’ç¼ºå¤±å€¼å¡«å……â†’æ—¶é—´æ ‡å‡†åŒ–
    æ»¡è¶³è¦æ±‚ï¼šæ— é‡å¤/ä¹±åºã€å‰”é™¤åˆä¼‘ã€ä»…ffillå¡«å……ã€æ–°å¢datetimeã€æ— NaN/0å¡«å……
    """
    # 1. åŠ è½½åŸå§‹æ•°æ®
    df = load_data(day, stock_code)
    if df.empty:
        print(f" {day}æ—¥-{stock_code} åŸå§‹æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
        return pd.DataFrame()
    
    # 2. åŸºç¡€æ¸…æ´—ï¼šå»é‡+æ—¶åºæ’åº
    df = df.drop_duplicates(subset=["Time"], keep="first")  # å»é‡é‡å¤æ—¶é—´æˆ³
    df = df.sort_values(by="Time", ascending=True).reset_index(drop=True)  # ä¸¥æ ¼å‡åº
    
    # 3. æ—¶æ®µè¿‡æ»¤ï¼šå®Œå…¨å‰”é™¤åˆä¼‘/ç›˜å‰/ç›˜åï¼Œä»…ä¿ç•™åˆè§„äº¤æ˜“æ—¶é—´
    df = df[
        ((df["Time"] >= TRADING_RULES["morning_start"]) & (df["Time"] <= TRADING_RULES["morning_end"])) |
        ((df["Time"] >= TRADING_RULES["afternoon_start"]) & (df["Time"] <= TRADING_RULES["afternoon_end"]))
    ].reset_index(drop=True)
    if df.empty:
        print(f"{day}æ—¥-{stock_code} æ— åˆè§„äº¤æ˜“æ—¶æ®µæ•°æ®ï¼Œè·³è¿‡")
        return pd.DataFrame()
    
    # 4. å¼‚å¸¸å€¼æ¸…æ´—ï¼šä¸¥æ ¼ç¬¦åˆä¸šåŠ¡è§„åˆ™
    df = df[
        (df["BidPrice1"] < df["AskPrice1"]) &  # ä¹°ä¸€ä»· < å–ä¸€ä»·
        (df[PRICE_COLS] > 0).all(axis=1) &     # æ‰€æœ‰ä»·æ ¼>0
        (df[VOLUME_COLS] >= 0).all(axis=1) &   # æ‰€æœ‰é‡èƒ½éè´Ÿ
        (df[BID_VOL_COLS] % 100 == 0).all(axis=1)  # ä¹°æ–¹æŒ‚å•é‡ä¸º100æ•´æ•°å€
    ].reset_index(drop=True)
    if df.empty:
        print(f"âš ï¸ {day}æ—¥-{stock_code} å¼‚å¸¸å€¼æ¸…æ´—åæ— æ•°æ®ï¼Œè·³è¿‡")
        return pd.DataFrame()
    
    # 5. ç”Ÿæˆ500msåŸºå‡†æ—¶é—´è½´ï¼ˆæ—©ç›˜+åˆç›˜ï¼Œå‰”é™¤åˆä¼‘ï¼‰
    def gen_500ms_timeaxis(start: int, end: int) -> list:
        """ç”ŸæˆHHMMSSmmmæ ¼å¼çš„500msé—´éš”æ—¶é—´è½´"""
        time_list = []
        current = start
        while current <= end:
            time_list.append(current)
            current += TIME_INTERVAL
            # å¤„ç†æ—¶é—´è¿›ä½ï¼ˆæ¯«ç§’â†’ç§’â†’åˆ†â†’æ—¶ï¼‰
            if current % 1000000 >= 60000:  # ç§’è¿›ä½ï¼ˆå¦‚xx:xx:59.500 â†’ xx:xx+1:00.000ï¼‰
                current += 40000
            if current % 100000000 >= 60000000:  # åˆ†è¿›ä½ï¼ˆå¦‚xx:59:59.500 â†’ xx+1:00:00.000ï¼‰
                current += 40000000
        return time_list
    # åˆå¹¶æ—©ç›˜+åˆç›˜æ—¶é—´è½´ï¼Œæ— åˆä¼‘
    full_timeaxis = gen_500ms_timeaxis(TRADING_RULES["morning_start"], TRADING_RULES["morning_end"]) + \
                    gen_500ms_timeaxis(TRADING_RULES["afternoon_start"], TRADING_RULES["afternoon_end"])
    df_timeaxis = pd.DataFrame({"Time": full_timeaxis})
    
    # 6. æ—¶åºå¯¹é½ï¼šå·¦è¿æ¥åŸºå‡†æ—¶é—´è½´ï¼Œä¿è¯500msä¸¥æ ¼é€’å¢
    df_aligned = pd.merge(df_timeaxis, df, on="Time", how="left")
    
    # 7. ç¼ºå¤±å€¼å¤„ç†ï¼šä»…å‰å‘å¡«å……ffillï¼ˆç»å¯¹ç¦æ­¢bfillï¼Œé¿å…æœªæ¥æ•°æ®æ³„éœ²ï¼‰
    df_aligned = df_aligned.ffill()
    # å¼€ç›˜é¦–è¡Œç¼ºå¤±ï¼šç”¨ç¬¬ä¸€æ¡æœ‰æ•ˆæ•°æ®å¡«å……ï¼ˆä»…1æ¬¡ï¼Œä¸è·¨æ—¶æ®µï¼‰
    df_aligned = df_aligned.bfill(limit=1)
    # å‰”é™¤æç«¯ç¼ºå¤±è¡Œ
    df_aligned = df_aligned.dropna().reset_index(drop=True)
    
    # 8. æ—¶é—´æ ‡å‡†åŒ–ï¼šæ–°å¢datetimeå­—æ®µï¼ˆHHMMSSmmmâ†’æ ‡å‡†æ—¶é—´æ ¼å¼ï¼‰ï¼Œä¸ä¿®æ”¹åŸå§‹Time
    day_date = f"2024-01-0{day}"  # è™šæ‹Ÿæ—¥æœŸï¼Œé¿å…è·¨äº¤æ˜“æ—¥æ—¶é—´å†²çª
    df_aligned["datetime"] = pd.to_datetime(
        day_date + " " + df_aligned["Time"].astype(str).str.zfill(9)
        .str.replace(r"(\d{2})(\d{2})(\d{2})(\d{3})", r"\1:\2:\3.\4", regex=True)
    )
    
    # 9. æ•°æ®ç±»å‹äºŒæ¬¡æ ¡å‡†ï¼Œé¿å…å¡«å……åç±»å‹å¼‚å¸¸
    df_aligned["Time"] = df_aligned["Time"].astype(np.int64)
    for col in PRICE_COLS + VOLUME_COLS + ORDER_NUM_COLS:
        df_aligned[col] = df_aligned[col].astype(np.int64)
    for col in AMOUNT_COLS:
        df_aligned[col] = df_aligned[col].astype(np.float64)
    
    # 10. ä¿å­˜å•è‚¡æ¸…æ´—åæ•°æ®
    save_path = os.path.join(OUTPUT_ROOT, day, "single_stock", f"{stock_code}_cleaned.csv")
    df_aligned.to_csv(save_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å•è‚¡å¤„ç†å®Œæˆï¼š{day}æ—¥-{stock_code}ï¼Œå¯¹é½åè¡Œæ•°ï¼š{df_aligned.shape[0]}")
    return df_aligned

# ===================== æ ¸å¿ƒ3ï¼šå¤šè‚¡å¤„ç†ï¼ˆä»¥Eä¸ºåŸºå‡†å¯¹é½ï¼Œç”Ÿæˆé¢æ¿æ•°æ®ï¼‰=====================
def process_multi_stock(day: str) -> pd.DataFrame:
    """
    å•äº¤æ˜“æ—¥å¤šè‚¡å¯¹é½ï¼šä»¥Eè‚¡æ—¶é—´è½´ä¸ºå”¯ä¸€åŸºå‡†ï¼Œåˆå¹¶A/B/C/D/Eæ•°æ®ï¼Œå­—æ®µåŠ åç¼€é¿å…å†²çª
    æ»¡è¶³è¦æ±‚ï¼šä¸€è¡Œä¸€ä¸ªæ—¶é—´æˆ³ã€EåŸç”Ÿå­—æ®µã€å…¶ä»–è‚¡åŠ åç¼€ã€æ— NaN/æ— åˆä¼‘ã€æ— æœªæ¥æ•°æ®
    """
    # 1. åŠ è½½å½“æ—¥æ‰€æœ‰è‚¡ç¥¨æ¸…æ´—åçš„æ•°æ®
    stock_data = {}
    for code in STOCK_CODES:
        file_path = os.path.join(OUTPUT_ROOT, day, "single_stock", f"{code}_cleaned.csv")
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"å•è‚¡æ¸…æ´—æ•°æ®ç¼ºå¤±ï¼š{file_path}")
        df = pd.read_csv(file_path, parse_dates=["datetime"])
        stock_data[code] = df
    
    # 2. ä»¥Eè‚¡ä¸ºåŸºå‡†ï¼ŒEä¿ç•™åŸç”Ÿå­—æ®µåï¼Œå…¶ä»–è‚¡ç¥¨å­—æ®µåŠ ã€_ä»£ç ã€‘åç¼€
    df_e = stock_data["E"].copy()
    for code in ["A", "B", "C", "D"]:
        df_temp = stock_data[code].copy()
        # ä»…å¯¹ä¸šåŠ¡å­—æ®µåŠ åç¼€ï¼Œæ—¶é—´å­—æ®µä¿ç•™åŸç”Ÿåç”¨äºå¯¹é½
        rename_cols = {col: f"{col}_{code}" for col in df_temp.columns if col not in ["Time", "datetime"]}
        df_temp = df_temp.rename(columns=rename_cols)
        # å·¦è¿æ¥ï¼šä¸¥æ ¼ä»¥Eè‚¡æ—¶é—´è½´ä¸ºåŸºå‡†ï¼Œä¿è¯æ—¶åºå®Œå…¨ä¸€è‡´
        df_e = pd.merge(df_e, df_temp, on=["Time", "datetime"], how="left")
    
    # 3. æœ€ç»ˆå¡«å……ï¼šä»…å‰å‘å¡«å……ï¼Œç¡®ä¿æ— NaN
    df_panel = df_e.ffill().dropna().reset_index(drop=True)
    
    # 4. ä¿å­˜å¤šè‚¡é¢æ¿æ•°æ®
    save_path = os.path.join(OUTPUT_ROOT, "multi_stock_panel", f"day_{day}_panel.csv")
    df_panel.to_csv(save_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å¤šè‚¡å¯¹é½å®Œæˆï¼š{day}æ—¥ï¼Œé¢æ¿ç»´åº¦ï¼š{df_panel.shape[0]}è¡Œ Ã— {df_panel.shape[1]}åˆ—")
    return df_panel

# ===================== æ ¸å¿ƒ4ï¼šè®¡ç®—åŸºæœ¬æŒ‡æ ‡ï¼ˆä¸­é—´ä»·/ä»·å·®/è®¢å•æµï¼‰=====================
def calculate_basic_indicators(df: pd.DataFrame, is_single_stock: bool = True, stock_code: str = None) -> pd.DataFrame:
    """
    è®¡ç®—é‡‘èåŸºç¡€æŒ‡æ ‡ï¼Œæ”¯æŒå•è‚¡æ•°æ®/å¤šè‚¡é¢æ¿æ•°æ®
    æŒ‡æ ‡ï¼šä¸­é—´ä»·ã€ç»å¯¹ä»·å·®ã€ç›¸å¯¹ä»·å·®ã€è®¢å•æµã€ç´¯è®¡è®¢å•æµ
    :param df: å•è‚¡æ¸…æ´—åæ•°æ® / å¤šè‚¡é¢æ¿æ•°æ®
    :param is_single_stock: æ˜¯å¦ä¸ºå•è‚¡æ•°æ®
    :param stock_code: å•è‚¡ä»£ç ï¼ˆA/B/C/D/Eï¼‰ï¼Œå¤šè‚¡æ—¶ä¸ºNone
    :return: å¸¦æŒ‡æ ‡çš„DataFrame
    """
    df_indicator = df.copy()
    prefix = "" if is_single_stock else f"{stock_code}_" if stock_code else ""
    
    # è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ï¼ˆåŸºäºä¹°ä¸€/å–ä¸€/æœ€æ–°ä»·ï¼Œæœ€å…·ä»£è¡¨æ€§ï¼‰
    bid1 = f"{prefix}BidPrice1"
    ask1 = f"{prefix}AskPrice1"
    last = f"{prefix}LastPrice"
    vol = f"{prefix}TradeBuyVolume" if is_single_stock else f"{prefix}TradeBuyVolume"
    
    # 1. ä¸­é—´ä»· = (ä¹°ä¸€ä»· + å–ä¸€ä»·) / 2
    df_indicator[f"{prefix}mid_price"] = (df_indicator[bid1] + df_indicator[ask1]) / 2
    # 2. ç»å¯¹ä»·å·® = å–ä¸€ä»· - ä¹°ä¸€ä»·
    df_indicator[f"{prefix}abs_spread"] = df_indicator[ask1] - df_indicator[bid1]
    # 3. ç›¸å¯¹ä»·å·® = ç»å¯¹ä»·å·® / ä¸­é—´ä»·ï¼ˆé¿å…é™¤é›¶ï¼ŒåŠ æå°å€¼ï¼‰
    df_indicator[f"{prefix}rel_spread"] = df_indicator[f"{prefix}abs_spread"] / (df_indicator[f"{prefix}mid_price"] + 1e-8)
    # 4. è®¢å•æµï¼šä¸»åŠ¨ä¹°=æ­£ï¼Œä¸»åŠ¨å–=è´Ÿï¼ˆæœ€æ–°ä»·â‰¥ä¸­é—´ä»·â†’ä¸»åŠ¨ä¹°ï¼Œåä¹‹ä¸»åŠ¨å–ï¼‰
    df_indicator[f"{prefix}order_flow"] = np.where(
        df_indicator[last] >= df_indicator[f"{prefix}mid_price"],
        df_indicator[vol],
        -df_indicator[vol]
    )
    # 5. ç´¯è®¡è®¢å•æµï¼ˆæ—¶åºç´¯è®¡ï¼Œåæ˜ èµ„é‡‘è¶‹åŠ¿ï¼‰
    df_indicator[f"{prefix}cum_order_flow"] = df_indicator[f"{prefix}order_flow"].cumsum()
    
    print(f" æŒ‡æ ‡è®¡ç®—å®Œæˆï¼š{('å•è‚¡' if is_single_stock else 'å¤šè‚¡')}ï¼Œæ–°å¢{5}ä¸ªåŸºç¡€æŒ‡æ ‡")
    return df_indicator

# ===================== ä¸»æµç¨‹ï¼šä¸€é”®æ‰§è¡Œå…¨æµç¨‹ =====================
def main():
    # 1. åˆå§‹åŒ–ç›®å½•
    init_directories()
    # 2. é€äº¤æ˜“æ—¥å¤„ç†ï¼šå•è‚¡æ¸…æ´— â†’ å¤šè‚¡å¯¹é½ â†’ æŒ‡æ ‡è®¡ç®—
    all_day_panel = []
    for day in tqdm(TRADING_DAYS, desc="å…¨æµç¨‹å¤„ç†è¿›åº¦"):
        print(f"\n===== å¼€å§‹å¤„ç†ã€{day}æ—¥ã€‘æ•°æ® =====")
        # 2.1 å•è‚¡æ‰¹é‡å¤„ç†
        for code in STOCK_CODES:
            df_single = process_single_stock(day, code)
            if not df_single.empty:
                # å•è‚¡æŒ‡æ ‡è®¡ç®—å¹¶ä¿å­˜
                df_single_indicator = calculate_basic_indicators(df_single, is_single_stock=True, stock_code=code)
                save_path = os.path.join(OUTPUT_ROOT, day, "single_stock", f"{code}_cleaned_indicator.csv")
                df_single_indicator.to_csv(save_path, index=False, encoding="utf-8-sig")
        # 2.2 å¤šè‚¡å¯¹é½
        df_panel = process_multi_stock(day)
        all_day_panel.append(df_panel)
        # 2.3 å¤šè‚¡é¢æ¿æŒ‡æ ‡è®¡ç®—ï¼ˆE+A/B/C/Dåˆ†åˆ«è®¡ç®—ï¼‰
        df_panel_indicator = df_panel.copy()
        # Eè‚¡æŒ‡æ ‡ï¼ˆåŸç”Ÿå­—æ®µï¼‰
        df_panel_indicator = calculate_basic_indicators(df_panel_indicator, is_single_stock=True, stock_code="")
        # A/B/C/Dè‚¡æŒ‡æ ‡ï¼ˆåŠ åç¼€ï¼‰
        for code in ["A", "B", "C", "D"]:
            df_panel_indicator = calculate_basic_indicators(df_panel_indicator, is_single_stock=False, stock_code=code)
        # ä¿å­˜å¤šè‚¡æŒ‡æ ‡é¢æ¿
        save_path = os.path.join(OUTPUT_ROOT, "indicators", f"day_{day}_panel_indicator.csv")
        df_panel_indicator.to_csv(save_path, index=False, encoding="utf-8-sig")
    
    # 3. åˆå¹¶æ‰€æœ‰äº¤æ˜“æ—¥çš„å¤šè‚¡é¢æ¿æ•°æ®ï¼ˆå¯ç›´æ¥ç”¨äºæ¨¡å‹è®­ç»ƒï¼‰
    df_full_panel = pd.concat(all_day_panel, axis=0).sort_values(by="datetime").reset_index(drop=True)
    df_full_panel.to_csv(os.path.join(OUTPUT_ROOT, "multi_stock_panel", "all_days_full_panel.csv"), 
                         index=False, encoding="utf-8-sig")
    # 4. åˆå¹¶æ‰€æœ‰äº¤æ˜“æ—¥æŒ‡æ ‡é¢æ¿
    df_full_indicator = []
    for day in TRADING_DAYS:
        df = pd.read_csv(os.path.join(OUTPUT_ROOT, "indicators", f"day_{day}_panel_indicator.csv"), parse_dates=["datetime"])
        df_full_indicator.append(df)
    df_full_indicator = pd.concat(df_full_indicator, axis=0).sort_values(by="datetime").reset_index(drop=True)
    df_full_indicator.to_csv(os.path.join(OUTPUT_ROOT, "indicators", "all_days_full_indicator.csv"), 
                             index=False, encoding="utf-8-sig")
    
    print(f"\n===== å…¨æµç¨‹å¤„ç†å®Œæˆ =====\nğŸ“ è¾“å‡ºæ ¹ç›®å½•ï¼š{OUTPUT_ROOT}\nğŸ“ˆ å…¨é‡é¢æ¿è¡Œæ•°ï¼š{df_full_panel.shape[0]}\nğŸ“Š å…¨é‡æŒ‡æ ‡é¢æ¿è¡Œæ•°ï¼š{df_full_indicator.shape[0]}")

# ===================== æ‰§è¡Œå…¥å£ =====================
if __name__ == "__main__":
    main()